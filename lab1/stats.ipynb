{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd02762fd0ccae7a6827a0de0868563b3d499c815e35640ddddc3d2dc7e9a34dcb9",
   "display_name": "Python 3.6.12 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import utils as ut\n",
    "import functions as fu \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "X_train, y_train, Y_train = ut.loadData('data_batch_1', clipping=True)\n",
    "X_val, y_val, Y_val = ut.loadData('data_batch_2', clipping=True)\n",
    "X_test, y_test, Y_test = ut.loadData('data_batch_3', clipping=True)\n",
    "\n",
    "## normalize with mean and std of train set \n",
    "mean_X = np.mean(X_train, axis=1)\n",
    "std_X = np.std(X_train, axis=1)\n",
    "\n",
    "X_train -= np.outer(mean_X, np.ones(X_train.shape[1]))\n",
    "X_train /= np.outer(std_X, np.ones(X_train.shape[1]))\n",
    "\n",
    "X_val -= np.outer(mean_X, np.ones(X_val.shape[1]))\n",
    "X_val /= np.outer(std_X, np.ones(X_val.shape[1]))\n",
    "\n",
    "X_test -= np.outer(mean_X, np.ones(X_test.shape[1]))\n",
    "X_test /= np.outer(std_X, np.ones(X_test.shape[1]))"
   ]
  },
  {
   "source": [
    "# Experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "\n",
    "GDparams = [{\"lambda\":0, \"n_epochs\":40, \"n_batch\":100, \"eta\":.1}, {\"lambda\":0, \"n_epochs\":40, \"n_batch\":100, \"eta\":.001}, \n",
    "          {\"lambda\":.1, \"n_epochs\":40, \"n_batch\":100, \"eta\":.001}, {\"lambda\":1, \"n_epochs\":40, \"n_batch\":100, \"eta\":.001}]\n",
    "\n",
    "np.random.seed(42)\n",
    "seeds = np.random.randint(0, 100, 5)\n",
    "stats = {i:{\"val_loss\":[], \"train_loss\":[], \"val_acc\":[], \"train_acc\":[], \"test_acc\":[]}for i in range(4)}\n",
    "\n",
    "for i, GDparam in enumerate(GDparams): \n",
    "    for seed in seeds:\n",
    "        np.random.seed(seed)\n",
    "        W = np.random.normal(mu, sigma, (K,d))\n",
    "        b = np.random.normal(mu, sigma, (K,1))\n",
    "        W, b, train_loss, val_loss, train_acc, val_acc = ut.minibatchGD(X_train, Y_train, y_train,  X_val, Y_val, y_val, GDparam, W, b, verbose=False)\n",
    "\n",
    "        stats[i][\"train_loss\"].append(train_loss[-1])\n",
    "        stats[i][\"val_loss\"].append(val_loss[-1])\n",
    "        stats[i][\"train_acc\"].append(train_acc[-1])\n",
    "        stats[i][\"val_acc\"].append(val_acc[-1])\n",
    "        stats[i][\"test_acc\"].append(ut.ComputeAccuracy(X_test, y_test, W, b))\n",
    "    \n",
    "    ut.montage(W, GDparam)\n",
    "    ut.plot_metric(train_loss, val_loss, GDparam, type=\"loss\")\n",
    "    ut.plot_metric(train_acc, val_acc, GDparam, type=\"accuracy\")\n",
    "np.save(\"History/stats.npy\", stats)"
   ]
  }
 ]
}