{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd02762fd0ccae7a6827a0de0868563b3d499c815e35640ddddc3d2dc7e9a34dcb9",
   "display_name": "Python 3.6.12 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import cPickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import utils as ut\n",
    "from tqdm import tqdm\n",
    "import mlp as mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K, d, n = 10, 3072, 10000\n",
    "np.random.seed(42)\n",
    "mu, sigma = 0, 0.01 \n",
    "batch_start, batch_end= 0, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X, mean, std):\n",
    "    X -= np.outer(mean_X, np.ones(X.shape[1]))\n",
    "    X /= np.outer(std_X, np.ones(X.shape[1]))\n",
    "    return X"
   ]
  },
  {
   "source": [
    "# Exercise 1: Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "X_train, y_train, Y_train = ut.loadData('data_batch_1', clipping=True)\n",
    "X_val, y_val, Y_val = ut.loadData('data_batch_2', clipping=True)\n",
    "X_test, y_test, Y_test = ut.loadData('test_batch', clipping=True)\n",
    "\n",
    "## normalize with mean and std of train set \n",
    "mean_X = np.mean(X_train, axis=1)\n",
    "std_X = np.std(X_train, axis=1)\n",
    "\n",
    "X_train = normalize_data(X_train, mean_X, std_X)\n",
    "X_val = normalize_data(X_val, mean_X, std_X)\n",
    "X_test = normalize_data(X_test, mean_X, std_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mlp)\n",
    "net = mlp.MLP()"
   ]
  },
  {
   "source": [
    "# Exercise 2: Compute the gradients for the network parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Exercise 3: Train your network with cyclical learning rules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Exercise 4: Train your network for real"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "X_train_whole, y_train_whole, Y_train_whole = ut.loadData('data_batch_1', clipping=True)\n",
    "X_test, y_test, Y_test = ut.loadData('test_batch', clipping=True)\n",
    "\n",
    "for i in range(2,6):\n",
    "    X, y, Y = ut.loadData('data_batch_'+str(i), clipping=True)\n",
    "    X_train_whole = np.concatenate((X, X_train_whole), axis=1)\n",
    "    y_train_whole = np.concatenate((y, y_train_whole))\n",
    "    Y_train_whole = np.concatenate((Y, Y_train_whole), axis=1)\n",
    "\n",
    "n_val = 5000\n",
    "\n",
    "X_val_small, y_val_small, Y_val_small = X_train_whole[:,-n_val:], y_train_whole[-n_val:], Y_train_whole[:,-n_val:]\n",
    "X_train_whole, y_train_whole, Y_train_whole = X_train_whole[:,:-n_val], y_train_whole[:-n_val], Y_train_whole[:,:-n_val]\n",
    "\n",
    "## normalize with mean and std of train set \n",
    "mean = np.mean(X_train_whole, axis=1)\n",
    "std = np.std(X_train_whole, axis=1)\n",
    "\n",
    "X_train_whole = normalize_data(X_train_whole, mean, std)\n",
    "X_val_small = normalize_data(X_val_small, mean, std)\n",
    "X_test = normalize_data(X_test, mean_X, std_X)"
   ]
  }
 ]
}